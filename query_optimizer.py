#!/usr/bin/env python3
"""
AI Query Optimizer - Multi-Query Generation for Improved Retrieval

This CLI tool generates 3 semantic variants of user queries using Grok API,
then performs similarity-based retrieval using sentence-transformers and FAISS.

Target: 20%+ improvement in recall accuracy per LangChain documentation.
"""

import os
import sys
import json
import time
import argparse
from typing import List, Dict, Tuple
import numpy as np

try:
    import requests
except ImportError:
    print("Error: 'requests' library not found. Install with: pip install requests")
    sys.exit(1)

try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    print("Error: 'sentence-transformers' not found. Install with: pip install sentence-transformers")
    sys.exit(1)

try:
    import faiss
except ImportError:
    print("Error: 'faiss-cpu' not found. Install with: pip install faiss-cpu")
    sys.exit(1)


class GrokQueryGenerator:
    """Generates query variants using Grok API."""
    
    def __init__(self, api_key: str, api_url: str = "https://api.x.ai/v1/chat/completions"):
        self.api_key = api_key
        self.api_url = api_url
        self.timeout = 10
        self.max_retries = 3
    
    def generate_variants(self, original_query: str) -> List[str]:
        """Generate 3 semantic variants of the original query."""
        
        prompt = f"""Given the following user query, generate exactly 3 alternative variants that will improve information retrieval.

Requirements for each variant:
1. Rephrase using different terminology while maintaining the core intent
2. Expand with specific details, context, or related concepts
3. Reformulate from a different perspective or angle

Original Query: "{original_query}"

Generate variants that are semantically distinct but preserve the original question's intent. Each variant should help retrieve different relevant documents.

Output format (exactly 3 variants, one per line):
Variant 1: [your variant here]
Variant 2: [your variant here]
Variant 3: [your variant here]"""

        payload = {
            "model": "grok-beta",
            "messages": [
                {
                    "role": "system",
                    "content": "You are an expert at query optimization for information retrieval systems. Generate diverse, high-quality query variants."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 500
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        for attempt in range(self.max_retries):
            try:
                print(f"ðŸ¤– Calling Grok API to generate query variants... (attempt {attempt + 1}/{self.max_retries})")
                response = requests.post(
                    self.api_url,
                    json=payload,
                    headers=headers,
                    timeout=self.timeout
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data['choices'][0]['message']['content']
                    variants = self._parse_variants(content)
                    
                    if len(variants) == 3:
                        print("âœ“ Successfully generated 3 query variants")
                        return variants
                    else:
                        print(f"âš  Warning: Expected 3 variants, got {len(variants)}. Retrying...")
                        
                elif response.status_code == 429:
                    wait_time = 2 ** attempt
                    print(f"âš  Rate limit hit. Waiting {wait_time}s before retry...")
                    time.sleep(wait_time)
                else:
                    print(f"âš  API error {response.status_code}: {response.text}")
                    
            except requests.exceptions.Timeout:
                print(f"âš  Request timeout on attempt {attempt + 1}")
                time.sleep(2 ** attempt)
            except Exception as e:
                print(f"âš  Error: {str(e)}")
                time.sleep(2 ** attempt)
        
        # Fallback: generate simple variants if API fails
        print("âš  API failed after retries. Using fallback variant generation...")
        return self._generate_fallback_variants(original_query)
    
    def _parse_variants(self, content: str) -> List[str]:
        """Parse variant strings from API response."""
        variants = []
        lines = content.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            # Look for lines starting with "Variant X:" or just containing substantial text
            if line.startswith("Variant"):
                # Extract text after the colon
                parts = line.split(':', 1)
                if len(parts) == 2:
                    variant_text = parts[1].strip().strip('"').strip("'")
                    if variant_text:
                        variants.append(variant_text)
            elif len(line) > 20 and not line.startswith("Original"):
                # Catch variants that might not have the "Variant X:" prefix
                variant_text = line.strip('"').strip("'").strip('-').strip()
                if variant_text and variant_text not in variants:
                    variants.append(variant_text)
        
        return variants[:3]  # Return only first 3
    
    def _generate_fallback_variants(self, query: str) -> List[str]:
        """Generate simple rule-based variants as fallback."""
        return [
            f"What are the key aspects of {query.lower().rstrip('?')}?",
            f"Explain the main concepts related to {query.lower().rstrip('?')}",
            f"Provide detailed information about {query.lower().rstrip('?')}"
        ]


class SemanticRetriever:
    """Handles embedding generation and FAISS-based retrieval."""
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        print(f"ðŸ“Š Loading embedding model: {model_name}...")
        self.model = SentenceTransformer(model_name)
        self.index = None
        self.documents = []
        print("âœ“ Embedding model loaded successfully")
    
    def build_index(self, documents: List[str]):
        """Build FAISS index from document collection."""
        print(f"ðŸ“š Building FAISS index for {len(documents)} documents...")
        self.documents = documents
        
        # Generate embeddings
        doc_embeddings = self.model.encode(documents, show_progress_bar=False)
        doc_embeddings = np.array(doc_embeddings).astype('float32')
        
        # Normalize for cosine similarity
        faiss.normalize_L2(doc_embeddings)
        
        # Build FAISS index
        dimension = doc_embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)  # Inner product = cosine similarity after normalization
        self.index.add(doc_embeddings)
        
        print(f"âœ“ FAISS index built with {self.index.ntotal} documents")
    
    def search(self, query: str, top_k: int = 5) -> List[Tuple[int, float, str]]:
        """Search for top-K most similar documents."""
        if self.index is None:
            raise ValueError("Index not built. Call build_index() first.")
        
        # Generate query embedding
        query_embedding = self.model.encode([query], show_progress_bar=False)
        query_embedding = np.array(query_embedding).astype('float32')
        faiss.normalize_L2(query_embedding)
        
        # Search
        scores, indices = self.index.search(query_embedding, top_k)
        
        # Return results: (doc_index, score, doc_text)
        results = []
        for idx, score in zip(indices[0], scores[0]):
            if idx < len(self.documents):  # Valid index
                results.append((int(idx), float(score), self.documents[idx]))
        
        return results


class QueryOptimizer:
    """Main orchestrator for multi-query optimization."""
    
    def __init__(self, grok_api_key: str, documents: List[str]):
        self.generator = GrokQueryGenerator(grok_api_key)
        self.retriever = SemanticRetriever()
        self.retriever.build_index(documents)
    
    def optimize(self, original_query: str, top_k: int = 5) -> Dict:
        """
        Run full optimization pipeline.
        
        Returns dict with:
        - original_query
        - variants
        - results per query
        - aggregated results
        - metrics
        """
        start_time = time.time()
        
        print("\n" + "="*70)
        print("AI QUERY OPTIMIZER - Multi-Query Retrieval")
        print("="*70)
        
        # Step 1: Generate variants
        print(f"\nðŸ“ Original Query: \"{original_query}\"")
        variants = self.generator.generate_variants(original_query)
        
        print("\nðŸ”„ Generated Variants:")
        for i, variant in enumerate(variants, 1):
            print(f"   {i}. {variant}")
        
        # Step 2: Retrieve for each query
        print(f"\nðŸ” Performing retrieval (top-{top_k} per query)...")
        
        all_queries = [original_query] + variants
        query_results = {}
        all_doc_indices = set()
        
        for i, query in enumerate(all_queries):
            query_label = "Original" if i == 0 else f"Variant {i}"
            results = self.retriever.search(query, top_k=top_k)
            query_results[query_label] = results
            
            # Track unique documents
            for doc_idx, score, _ in results:
                all_doc_indices.add(doc_idx)
            
            print(f"   âœ“ {query_label}: Retrieved {len(results)} documents")
        
        # Step 3: Aggregate and deduplicate results
        aggregated_results = self._aggregate_results(query_results)
        
        # Step 4: Calculate metrics
        baseline_docs = len(query_results["Original"])
        total_unique_docs = len(all_doc_indices)
        recall_improvement = ((total_unique_docs - baseline_docs) / baseline_docs * 100) if baseline_docs > 0 else 0
        
        processing_time = time.time() - start_time
        
        metrics = {
            "baseline_documents": baseline_docs,
            "total_unique_documents": total_unique_docs,
            "recall_improvement_pct": round(recall_improvement, 1),
            "processing_time_sec": round(processing_time, 2),
            "avg_similarity_score": round(np.mean([r[1] for r in aggregated_results]), 3) if aggregated_results else 0
        }
        
        return {
            "original_query": original_query,
            "variants": variants,
            "query_results": query_results,
            "aggregated_results": aggregated_results,
            "metrics": metrics
        }
    
    def _aggregate_results(self, query_results: Dict) -> List[Tuple[int, float, str, List[str]]]:
        """
        Aggregate results from all queries, keeping track of which queries retrieved each doc.
        
        Returns: List of (doc_idx, max_score, doc_text, retrieved_by_queries)
        """
        doc_scores = {}  # doc_idx -> (max_score, doc_text, set of query labels)
        
        for query_label, results in query_results.items():
            for doc_idx, score, doc_text in results:
                if doc_idx in doc_scores:
                    # Update max score and add query label
                    current_score, text, queries = doc_scores[doc_idx]
                    doc_scores[doc_idx] = (max(current_score, score), text, queries | {query_label})
                else:
                    doc_scores[doc_idx] = (score, doc_text, {query_label})
        
        # Convert to sorted list
        aggregated = [
            (doc_idx, score, text, sorted(list(queries)))
            for doc_idx, (score, text, queries) in doc_scores.items()
        ]
        
        # Sort by score (descending)
        aggregated.sort(key=lambda x: x[1], reverse=True)
        
        return aggregated


def print_results(results: Dict, verbose: bool = False):
    """Pretty print optimization results."""
    
    print("\n" + "="*70)
    print("ðŸ“‹ OPTIMIZED RETRIEVAL RESULTS")
    print("="*70)
    
    aggregated = results["aggregated_results"]
    
    print(f"\n{'Rank':<6} {'Doc ID':<8} {'Score':<8} {'Retrieved By':<40}")
    print("-" * 70)
    
    for rank, (doc_idx, score, doc_text, queries) in enumerate(aggregated[:10], 1):
        queries_str = ", ".join(queries)
        if len(queries_str) > 38:
            queries_str = queries_str[:35] + "..."
        print(f"{rank:<6} doc_{doc_idx:<4} {score:<8.3f} {queries_str:<40}")
        
        if verbose:
            # Print document excerpt
            excerpt = doc_text[:100] + "..." if len(doc_text) > 100 else doc_text
            print(f"       â””â”€ {excerpt}")
            print()
    
    # Print metrics
    metrics = results["metrics"]
    print("\n" + "="*70)
    print("ðŸ“ˆ PERFORMANCE METRICS")
    print("="*70)
    print(f"  â€¢ Baseline documents (single query):  {metrics['baseline_documents']}")
    print(f"  â€¢ Total unique documents (multi-query): {metrics['total_unique_documents']}")
    print(f"  â€¢ Recall improvement:                  +{metrics['recall_improvement_pct']}%")
    print(f"  â€¢ Average similarity score:            {metrics['avg_similarity_score']}")
    print(f"  â€¢ Total processing time:               {metrics['processing_time_sec']}s")
    print("="*70 + "\n")
    
    # Success indicator
    if metrics['recall_improvement_pct'] >= 20:
        print("âœ… SUCCESS: Achieved 20%+ recall improvement target!")
    else:
        print(f"âš ï¸  Below target: {metrics['recall_improvement_pct']}% improvement (target: 20%)")


def load_sample_documents() -> List[str]:
    """Load sample IPCC climate documents for testing."""
    return [
        "Climate change represents an urgent and potentially irreversible threat to human societies and the planet. The Intergovernmental Panel on Climate Change (IPCC) provides comprehensive assessments of climate science.",
        
        "Key risks from climate change include increased heat-related mortality, food insecurity from crop failures, water scarcity in drought-prone regions, and damage to critical infrastructure from extreme weather events.",
        
        "Sea level rise poses significant threats to coastal communities and small island nations. Projections indicate global mean sea level could rise by 0.43 to 0.84 meters by 2100 under moderate emission scenarios.",
        
        "Climate feedback mechanisms, such as ice-albedo feedback and permafrost thawing, can accelerate warming. As ice melts, darker surfaces absorb more solar radiation, creating a self-reinforcing cycle.",
        
        "Adaptation strategies must be implemented alongside mitigation efforts. These include building resilient infrastructure, developing drought-resistant crops, and establishing early warning systems for extreme weather.",
        
        "The primary driver of observed warming since the mid-20th century is anthropogenic greenhouse gas emissions, particularly CO2 from fossil fuel combustion and deforestation.",
        
        "Ecosystem disruption from climate change threatens biodiversity globally. Coral reefs face bleaching events from ocean warming, while shifting temperature zones force species migration and habitat loss.",
        
        "Economic impacts of climate change include reduced agricultural productivity, increased costs for coastal protection, higher insurance premiums, and disrupted supply chains from extreme weather events.",
        
        "Climate tipping points represent thresholds beyond which changes become irreversible on human timescales. Examples include Amazon rainforest dieback, Greenland ice sheet collapse, and Atlantic meridional overturning circulation shutdown.",
        
        "Mitigation requires rapid decarbonization across all sectors: transitioning to renewable energy, improving energy efficiency, electrifying transportation, and implementing carbon capture technologies.",
        
        "Social vulnerability to climate impacts varies by geography, income, and demographic factors. Low-income communities and developing nations face disproportionate risks despite contributing least to historical emissions.",
        
        "Climate models project temperature increases of 1.5Â°C to 4.5Â°C by 2100 depending on emission pathways. Limiting warming to 1.5Â°C requires achieving net-zero CO2 emissions by 2050.",
        
        "Ocean acidification from absorbed CO2 threatens marine ecosystems. Increasing acidity reduces calcium carbonate availability, impacting shellfish, corals, and organisms with calcium-based structures.",
        
        "Extreme weather event attribution science has advanced significantly, allowing researchers to quantify the influence of climate change on specific hurricanes, heat waves, and droughts.",
        
        "Climate justice principles emphasize that those least responsible for emissions face the greatest impacts. International climate agreements must address equity, capacity building, and technology transfer to developing nations."
    ]


def main():
    parser = argparse.ArgumentParser(
        description="AI Query Optimizer - Generate query variants for improved retrieval accuracy",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python query_optimizer.py --query "Key risks in climate reports?"
  python query_optimizer.py --query "What are climate feedback mechanisms?" --verbose
  python query_optimizer.py --query "Sea level rise projections" --top-k 3 --output results.json
        """
    )
    
    parser.add_argument(
        "--query",
        type=str,
        required=True,
        help="The user query to optimize"
    )
    
    parser.add_argument(
        "--top-k",
        type=int,
        default=5,
        help="Number of documents to retrieve per query (default: 5)"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Show document excerpts in results"
    )
    
    parser.add_argument(
        "--output",
        type=str,
        help="Save results to JSON file (optional)"
    )
    
    parser.add_argument(
        "--api-key",
        type=str,
        help="Grok API key (or set GROK_API_KEY environment variable)"
    )
    
    args = parser.parse_args()
    
    # Get API key
    api_key = args.api_key or os.getenv("GROK_API_KEY")
    if not api_key:
        print("âŒ Error: Grok API key not provided.")
        print("   Set GROK_API_KEY environment variable or use --api-key flag")
        print("   Example: export GROK_API_KEY='your-key-here'")
        sys.exit(1)
    
    # Load documents
    documents = load_sample_documents()
    
    # Run optimization
    optimizer = QueryOptimizer(api_key, documents)
    results = optimizer.optimize(args.query, top_k=args.top_k)
    
    # Display results
    print_results(results, verbose=args.verbose)
    
    # Save to file if requested
    if args.output:
        # Convert results to JSON-serializable format
        json_results = {
            "original_query": results["original_query"],
            "variants": results["variants"],
            "metrics": results["metrics"],
            "aggregated_results": [
                {
                    "doc_id": f"doc_{doc_idx}",
                    "score": score,
                    "retrieved_by": queries,
                    "text": text[:200] + "..." if len(text) > 200 else text
                }
                for doc_idx, score, text, queries in results["aggregated_results"]
            ]
        }
        
        with open(args.output, 'w') as f:
            json.dump(json_results, f, indent=2)
        print(f"ðŸ’¾ Results saved to: {args.output}")


if __name__ == "__main__":
    main()

